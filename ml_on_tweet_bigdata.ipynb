{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izvUgqlHGryC"
      },
      "source": [
        "## Instalación de ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bBS0t22Ib8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e35b8f6-7b62-4d8d-bc30-e434cfb8ff50"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7hxPTPGIkZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b7f031-cb14-4acc-eb6f-1264c04f198e"
      },
      "source": [
        "exec(open('/content/drive/MyDrive/Proyectos/Big_Data_ML.py').read())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active services:\n",
            "2881 NodeManager\n",
            "3154 Jps\n",
            "2713 NameNode\n",
            "2794 DataNode\n",
            "3051 JobHistoryServer\n",
            "2639 ResourceManager\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0SIWJwzksPj"
      },
      "source": [
        "\n",
        "## Visualización de datos en MySQL: *Hate Speech and Offensive Language Dataset*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8waOaU_gaQSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854ec4ae-976f-46e0-c352-404b50955505"
      },
      "source": [
        "!mysql -u root --password=password testdb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mysql: [Warning] Using a password on the command line interface can be insecure.\n",
            "Reading table information for completion of table and column names\n",
            "You can turn off this feature to get a quicker startup with -A\n",
            "\n",
            "Welcome to the MySQL monitor.  Commands end with ; or \\g.\n",
            "Your MySQL connection id is 16\n",
            "Server version: 8.0.39-0ubuntu0.22.04.1 (Ubuntu)\n",
            "\n",
            "Copyright (c) 2000, 2024, Oracle and/or its affiliates.\n",
            "\n",
            "Oracle is a registered trademark of Oracle Corporation and/or its\n",
            "affiliates. Other names may be trademarks of their respective\n",
            "owners.\n",
            "\n",
            "Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n",
            "\n",
            "mysql> SHOW DATABASES;\n",
            "+--------------------+\n",
            "| Database           |\n",
            "+--------------------+\n",
            "| information_schema |\n",
            "| mysql              |\n",
            "| performance_schema |\n",
            "| sys                |\n",
            "| testdb             |\n",
            "+--------------------+\n",
            "5 rows in set (0.01 sec)\n",
            "\n",
            "mysql> use testdb;\n",
            "Database changed\n",
            "mysql> SHOW TABLES;\n",
            "+------------------+\n",
            "| Tables_in_testdb |\n",
            "+------------------+\n",
            "| hate_speech      |\n",
            "+------------------+\n",
            "1 row in set (0.01 sec)\n",
            "\n",
            "mysql> SELECT * FROM hate_speech LIMIT 5;\n",
            "+----------+-------+-------------+--------------------+---------+-------+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| tweet_id | count | hate_speech | offensive_language | neither | class | tweet                                                                                                                                        |\n",
            "+----------+-------+-------------+--------------------+---------+-------+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|        0 |     3 |           0 |                  0 |       3 |     2 | !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out... |\n",
            "|        1 |     3 |           0 |                  3 |       0 |     1 | !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!                                                        |\n",
            "|        2 |     3 |           0 |                  3 |       0 |     1 | !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit                     |\n",
            "|        3 |     3 |           0 |                  2 |       1 |     1 | !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny                                                                               |\n",
            "|        4 |     6 |           0 |                  6 |       0 |     1 | !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;    |\n",
            "+----------+-------+-------------+--------------------+---------+-------+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "5 rows in set (0.00 sec)\n",
            "\n",
            "mysql> exit\n",
            "Bye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-r_Pmt_JUKG"
      },
      "source": [
        "\n",
        "Inserción de datos con Sqoop. El password de MySQL es \"password\" (sin comillas)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2YrBx52JVZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc956b67-162a-46bb-9b14-eff4629b6451"
      },
      "source": [
        "!sqoop import --connect jdbc:mysql://localhost/testdb --username root --password password --table hate_speech --hive-import --create-hive-table --hive-database default"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/11/11 05:03:51 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7\n",
            "24/11/11 05:03:51 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.\n",
            "24/11/11 05:03:51 INFO tool.BaseSqoopTool: Using Hive-specific delimiters for output. You can override\n",
            "24/11/11 05:03:51 INFO tool.BaseSqoopTool: delimiters with --fields-terminated-by, etc.\n",
            "24/11/11 05:03:52 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.\n",
            "24/11/11 05:03:52 INFO tool.CodeGenTool: Beginning code generation\n",
            "Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.\n",
            "24/11/11 05:03:53 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `hate_speech` AS t LIMIT 1\n",
            "24/11/11 05:03:53 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `hate_speech` AS t LIMIT 1\n",
            "24/11/11 05:03:53 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /content/hadoop\n",
            "Note: /tmp/sqoop-root/compile/4e8eef6739efd429602fa18b3766a7eb/hate_speech.java uses or overrides a deprecated API.\n",
            "Note: Recompile with -Xlint:deprecation for details.\n",
            "24/11/11 05:03:59 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-root/compile/4e8eef6739efd429602fa18b3766a7eb/hate_speech.jar\n",
            "24/11/11 05:03:59 WARN manager.MySQLManager: It looks like you are importing from mysql.\n",
            "24/11/11 05:03:59 WARN manager.MySQLManager: This transfer can be faster! Use the --direct\n",
            "24/11/11 05:03:59 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.\n",
            "24/11/11 05:03:59 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)\n",
            "24/11/11 05:03:59 INFO mapreduce.ImportJobBase: Beginning import of hate_speech\n",
            "24/11/11 05:04:00 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
            "24/11/11 05:04:02 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "24/11/11 05:04:02 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
            "24/11/11 05:04:10 INFO db.DBInputFormat: Using read commited transaction isolation\n",
            "24/11/11 05:04:10 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(`tweet_id`), MAX(`tweet_id`) FROM `hate_speech`\n",
            "24/11/11 05:04:10 INFO db.IntegerSplitter: Split size: 78563; Num splits: 4 from: 0 to: 314254\n",
            "24/11/11 05:04:11 INFO mapreduce.JobSubmitter: number of splits:4\n",
            "24/11/11 05:04:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1731301128566_0001\n",
            "24/11/11 05:04:12 INFO conf.Configuration: resource-types.xml not found\n",
            "24/11/11 05:04:12 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
            "24/11/11 05:04:12 INFO resource.ResourceUtils: Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE\n",
            "24/11/11 05:04:12 INFO resource.ResourceUtils: Adding resource type - name = vcores, units = , type = COUNTABLE\n",
            "24/11/11 05:04:13 INFO impl.YarnClientImpl: Submitted application application_1731301128566_0001\n",
            "24/11/11 05:04:13 INFO mapreduce.Job: The url to track the job: http://5454beba931e:8088/proxy/application_1731301128566_0001/\n",
            "24/11/11 05:04:13 INFO mapreduce.Job: Running job: job_1731301128566_0001\n",
            "24/11/11 05:04:27 INFO mapreduce.Job: Job job_1731301128566_0001 running in uber mode : false\n",
            "24/11/11 05:04:27 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "24/11/11 05:04:53 INFO mapreduce.Job:  map 25% reduce 0%\n",
            "24/11/11 05:04:54 INFO mapreduce.Job:  map 50% reduce 0%\n",
            "24/11/11 05:04:55 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "24/11/11 05:04:56 INFO mapreduce.Job: Job job_1731301128566_0001 completed successfully\n",
            "24/11/11 05:04:57 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=0\n",
            "\t\tFILE: Number of bytes written=869960\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\t\tHDFS: Number of bytes read=474\n",
            "\t\tHDFS: Number of bytes written=2244982\n",
            "\t\tHDFS: Number of read operations=16\n",
            "\t\tHDFS: Number of large read operations=0\n",
            "\t\tHDFS: Number of write operations=8\n",
            "\tJob Counters \n",
            "\t\tLaunched map tasks=4\n",
            "\t\tOther local map tasks=4\n",
            "\t\tTotal time spent by all maps in occupied slots (ms)=96693\n",
            "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
            "\t\tTotal time spent by all map tasks (ms)=96693\n",
            "\t\tTotal vcore-milliseconds taken by all map tasks=96693\n",
            "\t\tTotal megabyte-milliseconds taken by all map tasks=99013632\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=24776\n",
            "\t\tMap output records=24776\n",
            "\t\tInput split bytes=474\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=2010\n",
            "\t\tCPU time spent (ms)=11440\n",
            "\t\tPhysical memory (bytes) snapshot=807354368\n",
            "\t\tVirtual memory (bytes) snapshot=7541690368\n",
            "\t\tTotal committed heap usage (bytes)=637534208\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=2244982\n",
            "24/11/11 05:04:57 INFO mapreduce.ImportJobBase: Transferred 2.141 MB in 54.6017 seconds (40.152 KB/sec)\n",
            "24/11/11 05:04:57 INFO mapreduce.ImportJobBase: Retrieved 24776 records.\n",
            "24/11/11 05:04:57 INFO mapreduce.ImportJobBase: Publishing Hive/Hcat import job data to Listeners for table hate_speech\n",
            "24/11/11 05:04:57 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `hate_speech` AS t LIMIT 1\n",
            "24/11/11 05:04:57 INFO hive.HiveImport: Loading uploaded data into Hive\n",
            "24/11/11 05:04:57 INFO conf.HiveConf: Found configuration file file:/content/apache-hive-bin/conf/hive-site.xml\n",
            "24/11/11 05:04:57 WARN conf.HiveConf: HiveConf of name hive.enforce.bucketing does not exist\n",
            "24/11/11 05:05:01 INFO hive.HiveImport: SLF4J: Class path contains multiple SLF4J bindings.\n",
            "24/11/11 05:05:01 INFO hive.HiveImport: SLF4J: Found binding in [jar:file:/content/apache-hive-2.3.9-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "24/11/11 05:05:01 INFO hive.HiveImport: SLF4J: Found binding in [jar:file:/content/hadoop-2.10.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "24/11/11 05:05:01 INFO hive.HiveImport: SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "24/11/11 05:05:01 INFO hive.HiveImport: SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "24/11/11 05:05:09 INFO hive.HiveImport: \n",
            "24/11/11 05:05:09 INFO hive.HiveImport: Logging initialized using configuration in jar:file:/content/apache-hive-2.3.9-bin/lib/hive-common-2.3.9.jar!/hive-log4j2.properties Async: true\n",
            "24/11/11 05:05:24 INFO hive.HiveImport: OK\n",
            "24/11/11 05:05:24 INFO hive.HiveImport: Time taken: 12.888 seconds\n",
            "24/11/11 05:05:25 INFO hive.HiveImport: Loading data to table default.hate_speech\n",
            "24/11/11 05:05:25 INFO hive.HiveImport: OK\n",
            "24/11/11 05:05:25 INFO hive.HiveImport: Time taken: 1.094 seconds\n",
            "24/11/11 05:05:26 INFO hive.HiveImport: Hive import complete.\n",
            "24/11/11 05:05:26 INFO hive.HiveImport: Export directory is contains the _SUCCESS file only, removing the directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56HzogOHYaor"
      },
      "source": [
        "##  Visualización de datos con Hive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMeA6eGljJeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12802b42-9cbb-48c2-c40c-025b09883070"
      },
      "source": [
        "!hive -e \"SELECT * FROM hate_speech LIMIT 10;\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-2.3.9-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/content/hadoop-2.10.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-2.3.9-bin/lib/hive-common-2.3.9.jar!/hive-log4j2.properties Async: true\n",
            "OK\n",
            "hate_speech.class\thate_speech.count\thate_speech.hate_speech\thate_speech.neither\thate_speech.offensive_language\thate_speech.tweet\thate_speech.tweet_id\n",
            "2\t3\t0\t3\t0\t!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...\t0\n",
            "1\t3\t0\t0\t3\t!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!\t1\n",
            "1\t3\t0\t0\t3\t!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit\t2\n",
            "1\t3\t0\t1\t2\t!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny\t3\n",
            "1\t6\t0\t0\t6\t!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;\t4\n",
            "1\t3\t1\t0\t2\t\"!!!!!!!!!!!!!!!!!!\"\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &#128514;&#128514;&#128514;\"\"\"\t5\n",
            "1\t3\t0\t0\t3\t\"!!!!!!\"\"@__BrighterDays: I can not just sit up and HATE on another bitch .. I got too much shit going on!\"\"\"\t6\n",
            "1\t3\t0\t0\t3\t!!!!&#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls!!&#8221;\t7\n",
            "1\t3\t0\t0\t3\t\"\"\" &amp; you might not get ya bitch back &amp; thats that \"\"\"\t8\n",
            "1\t3\t1\t0\t2\t\"\"\" @rhythmixx_ :hobbies include: fighting Mariam\"\"\t9\n",
            "Time taken: 12.839 seconds, Fetched: 10 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-UxCQ8OlJai"
      },
      "source": [
        "## Lectura de datos con Spark SQL y separación train/test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqf85DDY5LX4"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import length\n",
        "\n",
        "spark = SparkSession.builder.enableHiveSupport().appName(\"MP-3\").getOrCreate()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeI5IS7A5q0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b203b1-f668-4c6f-e8ad-0d7edb8a7fb7"
      },
      "source": [
        "df_hate = spark.sql(\"SELECT * FROM hate_speech\")\n",
        "df_hate = df_hate.filter(df_hate[\"tweet\"].isNotNull() & (length(df_hate[\"tweet\"]) > 1))\n",
        "\n",
        "df_hate.show(10)\n",
        "\n",
        "training, testing = df_hate.randomSplit([0.95, 0.05], seed=100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+-------+------------------+--------------------+--------+\n",
            "|class|count|hate_speech|neither|offensive_language|               tweet|tweet_id|\n",
            "+-----+-----+-----------+-------+------------------+--------------------+--------+\n",
            "|    2|    3|          0|      3|                 0|!!! RT @mayasolov...|       0|\n",
            "|    1|    3|          0|      0|                 3|!!!!! RT @mleew17...|       1|\n",
            "|    1|    3|          0|      0|                 3|!!!!!!! RT @UrKin...|       2|\n",
            "|    1|    3|          0|      1|                 2|!!!!!!!!! RT @C_G...|       3|\n",
            "|    1|    6|          0|      0|                 6|!!!!!!!!!!!!! RT ...|       4|\n",
            "|    1|    3|          1|      0|                 2|\"!!!!!!!!!!!!!!!!...|       5|\n",
            "|    1|    3|          0|      0|                 3|\"!!!!!!\"\"@__Brigh...|       6|\n",
            "|    1|    3|          0|      0|                 3|!!!!&#8220;@selfi...|       7|\n",
            "|    1|    3|          0|      0|                 3|\"\"\" &amp; you mig...|       8|\n",
            "|    1|    3|          1|      0|                 2|\"\"\" @rhythmixx_ :...|       9|\n",
            "+-----+-----+-----------+-------+------------------+--------------------+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iccj4dmwZEQV"
      },
      "source": [
        "## Preprocesamiento de dataset de entrenamiento, con funciones de _tokenización_ y remoción de _stopwords_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YPEEGH0NP4H"
      },
      "source": [
        "from pyspark.ml.feature import RegexTokenizer\n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "\n",
        "tokenizer =RegexTokenizer(inputCol=\"tweet\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "\n",
        "stopWords=StopWordsRemover.loadDefaultStopWords('english')\n",
        "stopWordsRemover = StopWordsRemover(stopWords=stopWords, inputCol=\"words\", outputCol=\"clean_words\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x93bhsVBlFD"
      },
      "source": [
        "# tokenizer\n",
        "training_words = tokenizer.transform(training)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvSM_jUYMJ4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef6f2c7-af09-488c-f47c-e0be094fdbdb"
      },
      "source": [
        "# mostrar las columnas \"words\" y \"tweet\" de training_words\n",
        "training_words.select(\"words\", \"tweet\").show(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|               words|               tweet|\n",
            "+--------------------+--------------------+\n",
            "|[blackman38tide, ...|\"\"\"@Blackman38Tid...|\n",
            "|[nochillpaz, at, ...|\"\"\"@NoChillPaz: \"...|\n",
            "|[notoriousbm95, _...|\"\"\"@NotoriousBM95...|\n",
            "|[theomaxximus, ge...|\"\"\"@TheoMaxximus:...|\n",
            "|[ashlingwilde, it...|\"\"\"@ashlingwilde:...|\n",
            "|[bigbootybishopp,...|\"\"\"@bigbootybisho...|\n",
            "|[jayswaggkillah, ...|\"\"\"@jayswaggkilla...|\n",
            "|[jgabsss, stacey,...|\"\"\"@jgabsss: Stac...|\n",
            "|[don, t, worry, a...|\"\"\"Don't worry ab...|\n",
            "|[let, s, kill, cr...|\"\"\"Let's kill cra...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFO9XubcMNbh"
      },
      "source": [
        "# stopWordsRemover\n",
        "training_clean =stopWordsRemover.transform(training_words)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sbeCI6tN0xn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14cd4476-7060-4117-b159-ab0332053e19"
      },
      "source": [
        "from pyspark.sql.functions import size\n",
        "\n",
        "# Se usan finalmente aquellas frases con más de 3 palabras que no sean stopwords\n",
        "train_words = training_clean.filter(size(training_clean['clean_words']) > 3)\n",
        "train_words.show(n=5, truncate=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+-------+------------------+-----------------------------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "|class|count|hate_speech|neither|offensive_language|tweet                                                                                                                        |tweet_id|words                                                                                                                                      |clean_words                                                                                        |\n",
            "+-----+-----+-----------+-------+------------------+-----------------------------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "|0    |3    |2          |0      |1                 |\"\"\"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy11 queer\"\" gaywad\"                                                            |85      |[blackman38tide, whalelookyhere, howdydowdy11, queer, gaywad]                                                                              |[blackman38tide, whalelookyhere, howdydowdy11, queer, gaywad]                                      |\n",
            "|0    |3    |2          |0      |1                 |\"\"\"@NoChillPaz: \"\"At least I'm not a nigger\"\" http://t.co/RGJa7CfoiT\"\"                                                       |204     |[nochillpaz, at, least, i, m, not, a, nigger, http, t, co, rgja7cfoit]                                                                     |[nochillpaz, least, m, nigger, http, co, rgja7cfoit]                                               |\n",
            "|0    |3    |2          |0      |1                 |\"\"\"@NotoriousBM95: @_WhitePonyJr_ Ariza is a snake and a coward\"\" but at least he isn't a cripple like your hero Roach lmaoo\"|206     |[notoriousbm95, _whiteponyjr_, ariza, is, a, snake, and, a, coward, but, at, least, he, isn, t, a, cripple, like, your, hero, roach, lmaoo]|[notoriousbm95, _whiteponyjr_, ariza, snake, coward, least, isn, cripple, like, hero, roach, lmaoo]|\n",
            "|0    |3    |2          |0      |1                 |\"\"\"@TheoMaxximus: #GerrysHalloweenParty http://t.co/3ycrSrnjHc\"\" Halloween was yesterday stupid nigger\"                      |263     |[theomaxximus, gerryshalloweenparty, http, t, co, 3ycrsrnjhc, halloween, was, yesterday, stupid, nigger]                                   |[theomaxximus, gerryshalloweenparty, http, co, 3ycrsrnjhc, halloween, yesterday, stupid, nigger]   |\n",
            "|0    |3    |2          |0      |1                 |\"\"\"@ashlingwilde: @ItsNotAdam is bored supposed to be cute                                                                   |317     |[ashlingwilde, itsnotadam, is, bored, supposed, to, be, cute]                                                                              |[ashlingwilde, itsnotadam, bored, supposed, cute]                                                  |\n",
            "+-----+-----+-----------+-------+------------------+-----------------------------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-CAP88mbdBz"
      },
      "source": [
        "## Entrenamiento de modelo Word2Vec y transformación a features numéricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOI9aA5TN7DJ"
      },
      "source": [
        "from pyspark.ml.feature import Word2Vec\n",
        "\n",
        "model_w2v = Word2Vec(vectorSize=32, inputCol=\"clean_words\", outputCol=\"features\").fit(train_words)\n",
        "train_features = model_w2v.transform(train_words)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJwAlNXtWkFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67cdf538-f913-48eb-ac83-16af3e4ce455"
      },
      "source": [
        "# mostrar Dataframe final que se usará para entrenamiento\n",
        "train_features.select(\"features\").show(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|[-0.0040413890033...|\n",
            "|[-0.0152795820363...|\n",
            "|[-0.0236832043156...|\n",
            "|[-0.0318282336617...|\n",
            "|[-0.0504770226776...|\n",
            "|[-0.0093586333096...|\n",
            "|[-0.0416573341935...|\n",
            "|[-0.0781679417599...|\n",
            "|[-0.1047538125089...|\n",
            "|[-0.0651746609115...|\n",
            "+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWlKGWqZdCc1"
      },
      "source": [
        "## Entrenamiento de modelo clasificador RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1lkC7O6dGbc"
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "algorithm = RandomForestClassifier(numTrees=200, labelCol=\"class\", featuresCol=\"features\", predictionCol=\"prediction\")\n",
        "model = algorithm.fit(train_features)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27LL3o__eDpY"
      },
      "source": [
        "# obtener Dataframes de testing\n",
        "\n",
        "testing_words = tokenizer.transform(testing)\n",
        "testing_clean = stopWordsRemover.transform(testing_words)\n",
        "test_words = testing_clean.filter(size(testing_clean['clean_words']) > 3)\n",
        "test_features = model_w2v.transform(test_words)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFv6pDDLew-5"
      },
      "source": [
        "# obtener predicciones\n",
        "\n",
        "predictions =  model.transform(test_features)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWgoIbfwe8JF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38533bd3-6b75-41bc-83ea-91ff8ca6ca8c"
      },
      "source": [
        "# mostrar label, predicciones, y el tweet original\n",
        "\n",
        "predictions.select(\"class\", \"prediction\", \"tweet\").show(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+--------------------+\n",
            "|class|prediction|               tweet|\n",
            "+-----+----------+--------------------+\n",
            "|    0|       1.0|\"@BGALLY17 so ur ...|\n",
            "|    0|       1.0|\"@_SoulSurvivor_ ...|\n",
            "|    0|       1.0|\"@hekterr don't s...|\n",
            "|    0|       1.0|\"Everyone tells m...|\n",
            "|    0|       1.0|\"I feel sorry for...|\n",
            "|    0|       1.0|\"I hate when peop...|\n",
            "|    0|       2.0|\"Pantera - 5 Minu...|\n",
            "|    0|       1.0|#SomethingIGetAlo...|\n",
            "|    0|       1.0|&#8220;@kaylenden...|\n",
            "|    0|       1.0|&#8220;@kitty_hel...|\n",
            "+-----+----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XHHp7Lpfa7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c0a59f-4d4f-4051-b90b-e6636a63d88a"
      },
      "source": [
        "# evaluación con métrica de accuracy\n",
        "\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='class', metricName='accuracy')\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test accuracy: \", \"%2.1f%%\" % (accuracy * 100,))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy:  84.5%\n"
          ]
        }
      ]
    }
  ]
}